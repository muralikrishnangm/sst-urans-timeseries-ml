{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83045f87-b93f-41b9-b3c6-0d1da88c7a48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "**Python script for transforming training data for LSTM into that for NODE - URANS modeling of homogeneous SST**\n",
    "\n",
    "* **NOTE:** For NODE model. y0 is input and sequential data is output.\n",
    "\n",
    "* See [DataAcqu_LSTM.ipynb](DataAcqu_LSTM.ipynb) for details of generating data\n",
    "\n",
    "* This script loads the LSTM training data and converts into the format that NODE model uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39cc456a-d6c5-4772-a39c-aed556b6c390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data_funcs import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f872d85-9490-4e12-993a-5257dd69a001",
   "metadata": {
    "tags": []
   },
   "source": [
    "# User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf941f6a-c72d-4f5c-9dfa-4a964ba51ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HDdir           = '.'\n",
    "machine_dir     = 'Data_raw'    \n",
    "cases_train     = [1]\n",
    "# case 1 - F4R32, case 12 - F4R64, case 13 - F2R32; NOTE: see data_funcs.py\n",
    "Ntrainper       = 0.9             # number of training data (%)\n",
    "\n",
    "target_T        = 1               # target time period for sampling frequency\n",
    "seq_len_T       = 64               # target sequence length (sampling frequency) of LSTM input for target_T\n",
    "dt_target       = target_T/seq_len_T\n",
    "\n",
    "normEnergy      = True            # normalize inputs to dimension of energy and non-dimensionalize both i/p & o/p using total energy at initial state\n",
    "interpIO        = True            # interpolate data so that seq dt are same\n",
    "set_dt_seq      = True            # set dt for `interpIO` such that time length of `seq_len` data points = 1 time period\n",
    "dt_T            = 1.0               # dt for interpIO\n",
    "if set_dt_seq:\n",
    "    seq_len     = np.max([int(dt_T/dt_target), 1])  # sequence length (lag time) for LSTM input\n",
    "else:\n",
    "    seq_len     = seq_len_T   \n",
    "\n",
    "if seq_len==1:\n",
    "    raise Exception(f'Need more than 1 elements in the sequence for integration. '\\\n",
    "                    f'Current: seq_len_T={seq_len_T}, dt_T={dt_T}, seq_len={seq_len}. Exiting...')\n",
    "\n",
    "add_IP_time     = False           # add time info as an additional input\n",
    "add_IP_ke_pe_T  = False           # add ke and pe decay time scales as additional inputs (make sure the IPs are normalized)\n",
    "add_IP_Fr_Gn    = False           # add Frh and Gn as additional inputs\n",
    "\n",
    "shuffledata     = False           # randomly shuffle training data or not\n",
    "  \n",
    "savedata        = True\n",
    "\n",
    "\n",
    "# # Get case info and set savefilename\n",
    "numcases = len(cases_train)\n",
    "savefilename = f'{HDdir}/Data_training/RANSdata_shuffle{shuffledata}_in-Energy_NODE_seqlen{seq_len}_'\\\n",
    "            f'normEnergy{int(normEnergy)}_interpIO{int(interpIO)}_setdt{int(set_dt_seq)}-T{dt_T}_'\\\n",
    "            f'IPtime{int(add_IP_time)}_IPKEPEtime{int(add_IP_ke_pe_T)}_IPFrGn{int(add_IP_Fr_Gn)}'\n",
    "case_info = []\n",
    "for i in range(numcases):\n",
    "    case_info += [get_case_info(cases_train[i], machine_dir),]\n",
    "    savefilename += '_'+case_info[i].casename\n",
    "savefilename += f'_Ntrain{Ntrainper}.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8871c94-1e39-420b-a052-96b68b60b7ce",
   "metadata": {},
   "source": [
    "# Load LSTM data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf45d6f-2895-466c-a03b-f11662407cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(data, time):\n",
    "    # data is of dimnesion [batch, sequence, variables]\n",
    "    # time is of dimension [batch, sequence]\n",
    "    # output is of dimension [batch, sequence, variables]\n",
    "    data_dt = np.array([np.gradient(data[0,:,:], time[0,:], axis=0, edge_order=2)])\n",
    "    \n",
    "    # Loop over each depth dimension\n",
    "    for i in range(1, data.shape[0]):\n",
    "        # Compute the gradient along the time axis for the current depth\n",
    "        data_gradient = np.gradient(data[i,:,:], time[i,:], axis=0, edge_order=2)\n",
    "        # Append the gradient data for the current depth to the list\n",
    "        data_dt = np.append(data_dt, np.array([data_gradient]), axis=0)\n",
    "    return data_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e52a0b2-a001-4bcd-9493-93c699cc1306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data Data_training/RANSdata_shuffleFalse_in-Energy_LSTM_seqlen64_normEnergy1_interpIO1_setdt1-T1.0_IPtime0_IPKEPEtime0_IPFrGn0_F4R32_Ntrain0.9.npz\n",
      "Length of F4R32 dataset: 1671\n",
      "Length of full dataset: 1671\n"
     ]
    }
   ],
   "source": [
    "loaddatapath = f'Data_training/RANSdata_shuffle{shuffledata}_in-Energy_LSTM_seqlen{seq_len}_'\\\n",
    "            f'normEnergy{int(normEnergy)}_interpIO{int(interpIO)}_setdt{int(set_dt_seq)}-T{dt_T}_'\\\n",
    "            f'IPtime{int(add_IP_time)}_IPKEPEtime{int(add_IP_ke_pe_T)}_IPFrGn{int(add_IP_Fr_Gn)}'\n",
    "Ntrain_list = np.zeros((numcases)).astype(int)\n",
    "\n",
    "# Initialize data with first case\n",
    "# =====================\n",
    "j = 0\n",
    "loaddatafname = f'{loaddatapath}_{case_info[j].casename}_Ntrain{Ntrainper}.npz'\n",
    "print(f\"Loading data {loaddatafname}\")\n",
    "npzfile = np.load(loaddatafname)\n",
    "\n",
    "data_ip_varnames = npzfile['data_ip_varnames']\n",
    "data_dy_varnames = npzfile['data_op_varnames']\n",
    "\n",
    "# Extract data for NODE model\n",
    "ninputs = npzfile['datatrain_IP'].shape[2]\n",
    "ndydt = npzfile['datatrain_OP'].shape[1]\n",
    "Ntrain = npzfile['datatrain_IP'].shape[0]\n",
    "Ntest = npzfile['datatest_IP'].shape[0]\n",
    "data_time = npzfile['data_time']   # full time data\n",
    "\n",
    "# batched time data\n",
    "batch_t = np.zeros([len(data_time)-seq_len+1, seq_len])\n",
    "for i in range(len(data_time)-seq_len+1):\n",
    "    batch_t[i,:] = data_time[i:i+seq_len]\n",
    "\n",
    "# extract training data: state variables from the LSTM data\n",
    "datatrain_IP = npzfile['datatrain_IP'][:,0,:]    # inputs: initial conditions of states (first value of inputs of LSTM data)\n",
    "datatrain_OP = npzfile['datatrain_IP'][:,:,:]   # outputs: time series of states/inputs (full input seq of LSTM data)\n",
    "datatrain_time = batch_t[0:Ntrain,:]\n",
    "datatrain_dydt = get_gradient(npzfile['datatrain_IP'], datatrain_time) # np.gradient(npzfile['datatrain_IP'][:,:,:], datatrain_time[:,0], edge_order=2, axis=0)   # dydt\n",
    "\n",
    "# extract testing data: state variables from the LSTM data\n",
    "datatest_IP = npzfile['datatest_IP'][:,0,:]    # inputs: initial conditions of states (first value of inputs of LSTM data)\n",
    "datatest_OP = npzfile['datatest_IP'][:,:,:]   # outputs: time series of states/inputs (full input seq of LSTM data)\n",
    "datatest_time = batch_t[Ntrain:Ntrain+Ntest,:]\n",
    "datatest_dydt = get_gradient(npzfile['datatest_IP'], datatest_time) # np.gradient(datatest_IP[:,:], datatest_time[:,0], edge_order=2, axis=0)   # dydt\n",
    "\n",
    "Ntrain_list[j]    = Ntrain\n",
    "print(f\"Length of {case_info[j].casename} dataset: {Ntrain_list[j]}\")\n",
    "\n",
    "# Loop over all cases\n",
    "# =====================\n",
    "for j in range(1,numcases):\n",
    "    loaddatafname = f'{loaddatapath}_{case_info[j].casename}_Ntrain{Ntrainper}.npz'\n",
    "    print(f\"Loading data {loaddatafname}\")\n",
    "    npzfile = np.load(loaddatafname)\n",
    "    \n",
    "    data_ip_varnames = npzfile['data_ip_varnames']\n",
    "    data_dy_varnames = npzfile['data_op_varnames']\n",
    "    \n",
    "    # Extract data for NODE model\n",
    "    ninputs = npzfile['datatrain_IP'].shape[2]\n",
    "    ndydt = npzfile['datatrain_OP'].shape[1]\n",
    "    Ntrain = npzfile['datatrain_IP'].shape[0]\n",
    "    Ntest = npzfile['datatest_IP'].shape[0]\n",
    "    data_time_case = npzfile['data_time']   # full time data\n",
    "    data_time = np.append(data_time, data_time_case, axis=0)   # dydt\n",
    "    \n",
    "    # batched time data\n",
    "    batch_t = np.zeros([len(data_time_case)-seq_len+1, seq_len])\n",
    "    for i in range(len(data_time_case)-seq_len+1):\n",
    "        batch_t[i,:] = data_time_case[i:i+seq_len]\n",
    "    \n",
    "    # extract training data: state variables from the LSTM data\n",
    "    datatrain_IP_case = npzfile['datatrain_IP'][:,0,:]    # inputs: initial conditions of states (first value of inputs of LSTM data)\n",
    "    datatrain_OP_case = npzfile['datatrain_IP'][:,:,:]   # outputs: time series of states/inputs (full input seq of LSTM data)\n",
    "    datatrain_time_case = batch_t[0:Ntrain,:]\n",
    "    datatrain_dydt_case = get_gradient(npzfile['datatrain_IP'], datatrain_time_case) # np.gradient(datatrain_IP_case[:,:], datatrain_time_case[:,0], edge_order=2, axis=0)   # dydt\n",
    "    datatrain_IP = np.append(datatrain_IP, datatrain_IP_case, axis=0)    # inputs: initial conditions of states (first value of inputs of LSTM data)\n",
    "    datatrain_OP = np.append(datatrain_OP, datatrain_OP_case, axis=0)   # outputs: time series of states/inputs (full input seq of LSTM data)\n",
    "    datatrain_time = np.append(datatrain_time, datatrain_time_case, axis=0)\n",
    "    datatrain_dydt = np.append(datatrain_dydt, datatrain_dydt_case, axis=0)   # dydt\n",
    "    \n",
    "    # extract testing data: state variables from the LSTM data\n",
    "    datatest_IP_case = npzfile['datatest_IP'][:,0,:]    # inputs: initial conditions of states (first value of inputs of LSTM data)\n",
    "    datatest_OP_case = npzfile['datatest_IP'][:,:,:]   # outputs: time series of states/inputs (full input seq of LSTM data)\n",
    "    datatest_time_case = batch_t[Ntrain:Ntrain+Ntest,:]\n",
    "    datatest_dydt_case = get_gradient(npzfile['datatest_IP'], datatest_time_case) # np.gradient(datatest_IP_case[:,:], datatest_time_case[:,0], edge_order=2, axis=0)   # dydt\n",
    "    datatest_IP = np.append(datatest_IP, datatest_IP_case, axis=0)    # inputs: initial conditions of states (first value of inputs of LSTM data)\n",
    "    datatest_OP = np.append(datatest_OP, datatest_OP_case, axis=0)   # outputs: time series of states/inputs (full input seq of LSTM data)\n",
    "    datatest_time = np.append(datatest_time, datatest_time_case, axis=0)\n",
    "    datatest_dydt = np.append(datatest_dydt, datatest_dydt_case, axis=0)   # dydt\n",
    "    \n",
    "    Ntrain_list[j]    = Ntrain\n",
    "    print(f\"Length of {case_info[j].casename} dataset: {Ntrain_list[j]}\")\n",
    "\n",
    "Ntrain = len(datatrain_time)\n",
    "print(f\"Length of full dataset: {Ntrain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bbb92b-bfce-4831-97cf-ec2eb0807531",
   "metadata": {},
   "source": [
    "# Save data to npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb066ed-b3ad-44cf-9a78-2f2c2521aa36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Data saved===========\n"
     ]
    }
   ],
   "source": [
    "if savedata == True:\n",
    "    if numcases==1:\n",
    "        np.savez(savefilename, \n",
    "             datatrain_IP=datatrain_IP, datatrain_OP=datatrain_OP, datatrain_dydt=datatrain_dydt, datatrain_time=datatrain_time,\n",
    "             datatest_IP=datatest_IP, datatest_OP=datatest_OP, datatest_dydt=datatest_dydt, datatest_time=datatest_time,\n",
    "             data_time=data_time, data_ip_varnames=data_ip_varnames, data_dy_varnames=data_dy_varnames,\n",
    "             nu=case_info[0].nu, drhobardz=case_info[0].drhobardz, accel=case_info[0].accel, rho0=case_info[0].rho0, \n",
    "             totalE=npzfile['totalE'], Frh=npzfile['Frh'], Gn=npzfile['Gn'])\n",
    "    else:\n",
    "        np.savez(savefilename, \n",
    "                 datatrain_IP=datatrain_IP, datatrain_OP=datatrain_OP, datatrain_dydt=datatrain_dydt, datatrain_time=datatrain_time,\n",
    "                 datatest_IP=datatest_IP, datatest_OP=datatest_OP, datatest_dydt=datatest_dydt, datatest_time=datatest_time,\n",
    "                 data_time=data_time, data_ip_varnames=data_ip_varnames, data_dy_varnames=data_dy_varnames)\n",
    "    print(\"===========Data saved===========\")\n",
    "else: \n",
    "    print(\"===========Data not saved===========\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sst-urans-ml",
   "language": "python",
   "name": "sst-urans-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
